
from pathlib import Path

# Read configuration
configfile: "config/config.yaml"

SOURCEDIR = Path(config["sourcedir"])
OUTDIR = Path(config["results"])
READSDIR = Path(config["readsdir"])
genome_fasta = Path(config["genome_fasta"])
existing_annotation = Path(config["existing_annotation"])


READS = [filepath for filepath in Path(READSDIR).glob('**/*')]

rule all:
    input:
        # clean_sam = expand( OUTDIR / "TALON" / "cleaned_alignments" / "{sample}" / "{sample}_clean.sam", sample=[ ".".join(read.name.split('.')[:-1]) for read in READS]),
        # database = OUTDIR / "TALON" / "talon.db",
        # OUTDIR / "TALON" / "config.csv",
        # database_ann = OUTDIR / "TALON" / "ann_talon.db"
        # filtered_transcripts = OUTDIR / "TALON" / "filtered_transcripts.csv"
        abundance=OUTDIR / "TALON" / 'filtered_talon_abundance_filtered.tsv',
        GTF = OUTDIR / "TALON" / 'filtered_talon.gtf'
        # labeled_sam = expand(OUTDIR / "TALON" / "labeled" / "{sample}_labeled.sam",sample=[read.name.split('.')[0] for read in READS]),
        # config = OUTDIR / "TALON" / "config.csv",
        # database = OUTDIR / "TALON" / "talon.db"


rule minimap2_align:
    input:
        genome = genome_fasta,
        fq = READSDIR / "{sample}.fastq"
    params:
        outdir = OUTDIR,
        opts = config["minimap2_opts"]
    output:
        sam_files = OUTDIR / "alignments" /"{sample}.sam"
    threads: 10
    singularity:
        'docker://quay.io/biocontainers/minimap2:2.17--h5bf99c6_4'
    shell:
        '''
        minimap2 \
            -t {threads} \
            -ax splice \
            {params.opts} \
            {input.genome} \
            {input.fq} > {output.sam_files}
        '''


# TALON
rule get_SJs_from_gtf:
    input:
        annotation = existing_annotation,
        genome = genome_fasta
    params:
        outdir = OUTDIR
    output:
        splicejns = OUTDIR / "TALON" / "cleaned_alignments" / "spliceJns.txt"
    threads: 1
    singularity:
        "docker://biocontainers/transcriptclean:v2.0.2_cv1"
    shell:
        '''
        get_SJs_from_gtf \
            --f {input.annotation} \
            --g {input.genome} \
            --o {output.splicejns}
        '''

rule transcriptclean:
    input:
        sam_files = rules.minimap2_align.output.sam_files,
        genome = genome_fasta,
        splicejns = rules.get_SJs_from_gtf.output.splicejns
    params:
        outdir = lambda wildcards: OUTDIR / "TALON" / "cleaned_alignments" / wildcards.sample / wildcards.sample
    output:
        clean_sam = OUTDIR / "TALON" /"cleaned_alignments" / "{sample}" / "{sample}_clean.sam"
    threads: 10
    singularity:
        "docker://biocontainers/transcriptclean:v2.0.2_cv1"
    shell:
        '''
        TranscriptClean \
            --sam {input.sam_files} \
            --genome {input.genome} \
            -t {threads} \
            --spliceJns {input.splicejns} \
            --outprefix {params.outdir}
        '''

rule talon_label_reads:
    input:
        clean_sam = rules.transcriptclean.output.clean_sam,
        genome = genome_fasta
    params:
        outdir = lambda wildcards: OUTDIR / "TALON" / "labeled" / wildcards.sample
    output:
        labeled_sam = OUTDIR / "TALON" / "labeled" / "{sample}_labeled.sam",
    threads: 10
    singularity:
        "docker://biocontainers/talon:v5.0_cv1"
    shell:
        '''
        mkdir -p labeled
        talon_label_reads \
            --f {input.clean_sam}\
            --g {input.genome} \
            --t {threads} \
            --ar 20 \
            --o {params.outdir}
        '''

rule create_talon_config:
    input:
        labels = expand(OUTDIR / "TALON" / "labeled" / "{sample}_labeled.sam",sample=[".".join(read.name.split('.')[:-1]) for read in READS]),
    params:
        datasetnames= [".".join(read.name.split('.')[:-1]) for read in READS]
    output:
        config = OUTDIR / "TALON" / "config.csv",
    threads: 1
    run:
        for label, name in zip(input.labels, params.datasetnames):
            with open(output.config, 'a+') as config:
                config.write("%s,%s,ONT,%s\n" % (name, name, label))

rule talon_initialize_annotate_database:
    input:
        annotation = existing_annotation,
        config = rules.create_talon_config.output.config
    params:
        outdir = OUTDIR / "TALON" / "talon",
        dbloc = OUTDIR / "TALON" / "talon.db",
        annotation_name = existing_annotation.name.split('.')[0],
        genome_name = genome_fasta.name.split('.')[0],
    output:
        database = OUTDIR / "TALON" / "talon.db"
    threads: 4
    singularity:
        "docker://biocontainers/talon:v5.0_cv1"
    shell:
        '''
        
        talon_initialize_database \
            --f {input.annotation} \
            --a {params.annotation_name} \
            --g {params.genome_name} \
            --5p 500 \
            --3p 300 \
            --o {params.outdir}
        echo "completed init"
        
        talon \
            --f {input.config} \
            --db {params.dbloc} \
            --build {params.genome_name} \
            --o {params.outdir} \
            -t {threads}
        echo "completed annot"
        '''

rule talon_filter_transcripts:
    input:
        db = rules.talon_initialize_annotate_database.output.database
    params:
        outdir = OUTDIR,
        datasetnames= [".".join(read.name.split('.')[:-1]) for read in READS],
        mincount= config["mincounts"],
        mindatasets= config["mindatasets"],
        annotation_name = existing_annotation.name.split('.')[0],
    output:
        filtered_transcripts = OUTDIR / "TALON" / "filtered_transcripts.csv"
    threads: 1
    singularity:
        "docker://biocontainers/talon:v5.0_cv1"
    shell:
        '''
        talon_filter_transcripts \
            --db {input.db} \
            --datasets {params.datasetnames} \
            -a {params.annotation_name} \
            --maxFracA 0.5 \
            --minCount {params.mincount} \
            --minDatasets {params.mindatasets} \
            --o {output.filtered_transcripts}
        '''

rule talon_abundance:
    input:
        db = rules.talon_initialize_annotate_database.output.database,
        filter = rules.talon_filter_transcripts.output.filtered_transcripts
    params:
        outdir = OUTDIR / "TALON" / 'filtered',
        annotation_name = existing_annotation.name.split('.')[0],
    output:
        abundance = OUTDIR / "TALON" / 'filtered_talon_abundance_filtered.tsv'
    singularity:
        "docker://biocontainers/talon:v5.0_cv1"
    shell:
        '''
        talon_abundance \
            --db {input.db} \
            --whitelist {input.filter} \
            -a {params.annotation_name} \
            --build "SIRV" \
            --o {params.outdir}
        '''

rule talon_create_GTF:
    input:
        db = rules.talon_initialize_annotate_database.output.database,
        filter= rules.talon_filter_transcripts.output.filtered_transcripts
    params:
        outdir = OUTDIR / "TALON" / 'filtered',
        annotation_name = existing_annotation.name.split('.')[0],
    output:
        GTF = OUTDIR / "TALON" / 'filtered_talon.gtf'
    singularity:
        "docker://biocontainers/talon:v5.0_cv1"
    shell:
        '''
        talon_create_GTF \
            --db {input.db} \
            --whitelist {input.filter} \
            -a {params.annotation_name} \
            --build "SIRV" \
            --o {params.outdir}
        '''

